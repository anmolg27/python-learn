{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43edadd0",
   "metadata": {},
   "source": "# Python Standard Library - Comprehensive Guide\n\n## What is the Standard Library?\n\nThe Python Standard Library is a vast collection of modules and packages that come bundled with Python installation. It provides a rich set of functionality covering everything from basic data types to advanced networking, from file operations to web development tools. The philosophy is \"batteries included\" - Python comes with everything you need for most common programming tasks.\n\n## Key Categories of Standard Library Modules\n\n### 1. **Built-in Data Structures & Algorithms**\n- `array`, `collections`, `heapq`, `bisect`\n\n### 2. **Text Processing & Pattern Matching**\n- `re`, `string`, `difflib`, `textwrap`\n\n### 3. **Mathematics & Numbers**\n- `math`, `decimal`, `fractions`, `statistics`, `random`\n\n### 4. **Date & Time**\n- `datetime`, `time`, `calendar`\n\n### 5. **File & Directory Access**\n- `os`, `pathlib`, `shutil`, `glob`, `tempfile`\n\n### 6. **Data Serialization & Persistence**\n- `json`, `pickle`, `csv`, `sqlite3`, `xml`\n\n### 7. **Internet & Networking**\n- `urllib`, `http`, `email`, `socket`\n\n### 8. **System & Operating System**\n- `sys`, `platform`, `subprocess`, `threading`, `multiprocessing`\n\n### 9. **Development & Debugging Tools**\n- `unittest`, `logging`, `pdb`, `profile`, `timeit`\n\n---\n\n## Detailed Module Exploration"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "93c9607a",
   "metadata": {},
   "outputs": [],
   "source": "## 1. Array Module - Efficient Numeric Arrays\n\nThe `array` module provides space-efficient arrays of basic values: characters, integers, floating point numbers. Arrays are sequence types that store values of the same type more compactly than lists.\n\n**Key Features:**\n- More memory efficient than lists for large collections of numbers\n- Type-specific storage (integers, floats, etc.)\n- Supports all sequence operations\n- Can be written to and read from files efficiently\n\n**Type Codes:**\n- 'i': signed int (typically 4 bytes)\n- 'f': float (4 bytes)  \n- 'd': double (8 bytes)\n- 'u': Unicode character (2 or 4 bytes)\n- 'b': signed char (1 byte)\n- 'B': unsigned char (1 byte)"
  },
  {
   "cell_type": "code",
   "id": "vlip8jb0cnl",
   "source": "import array\nimport sys\n\n# Create different types of arrays\nint_array = array.array('i', [1, 2, 3, 4, 5])\nfloat_array = array.array('f', [1.1, 2.2, 3.3, 4.4])\ndouble_array = array.array('d', [1.123456789, 2.987654321])\n\nprint(\"Integer array:\", int_array)\nprint(\"Float array:\", float_array)  \nprint(\"Double array:\", double_array)\n\n# Memory efficiency comparison\nregular_list = [1, 2, 3, 4, 5] * 1000\narray_data = array.array('i', [1, 2, 3, 4, 5] * 1000)\n\nprint(f\"\\nMemory usage comparison (5000 integers):\")\nprint(f\"Regular list: {sys.getsizeof(regular_list)} bytes\")\nprint(f\"Array: {sys.getsizeof(array_data)} bytes\")\n\n# Array operations\nprint(f\"\\nArray operations:\")\nprint(f\"Length: {len(int_array)}\")\nprint(f\"First element: {int_array[0]}\")\nprint(f\"Last element: {int_array[-1]}\")\n\n# Append and extend\nint_array.append(6)\nint_array.extend([7, 8, 9])\nprint(f\"After append and extend: {int_array}\")\n\n# Convert to list\nas_list = int_array.tolist()\nprint(f\"Converted to list: {as_list}, type: {type(as_list)}\")\n\n# Buffer info (memory address and length)\nprint(f\"Buffer info: {int_array.buffer_info()}\")\nprint(f\"Type code: {int_array.typecode}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "3a8f6c28",
   "metadata": {},
   "outputs": [],
   "source": "## 2. Math Module - Mathematical Functions & Constants\n\nThe `math` module provides mathematical functions and constants for real numbers. It's implemented in C, making it very fast for mathematical computations.\n\n**Key Categories:**\n- **Number-theoretic functions**: `factorial()`, `gcd()`, `lcm()`\n- **Power and logarithmic functions**: `pow()`, `log()`, `log10()`, `exp()`  \n- **Trigonometric functions**: `sin()`, `cos()`, `tan()`, `asin()`, `acos()`, `atan()`\n- **Angular conversion**: `degrees()`, `radians()`\n- **Hyperbolic functions**: `sinh()`, `cosh()`, `tanh()`\n- **Special functions**: `gamma()`, `erf()`, `isfinite()`, `isnan()`, `isinf()`\n- **Constants**: `pi`, `e`, `tau`, `inf`, `nan`"
  },
  {
   "cell_type": "code",
   "id": "ulr0l9zolki",
   "source": "import math\n\n# Constants\nprint(\"Mathematical Constants:\")\nprint(f\"π (pi): {math.pi}\")\nprint(f\"e (Euler's number): {math.e}\")\nprint(f\"τ (tau): {math.tau}\")  # 2 * π\nprint(f\"Infinity: {math.inf}\")\nprint(f\"Not a Number: {math.nan}\")\n\n# Basic operations\nprint(f\"\\nBasic Operations:\")\nprint(f\"Square root of 16: {math.sqrt(16)}\")\nprint(f\"2 raised to power 8: {math.pow(2, 8)}\")\nprint(f\"Ceiling of 4.3: {math.ceil(4.3)}\")\nprint(f\"Floor of 4.7: {math.floor(4.7)}\")\nprint(f\"Factorial of 5: {math.factorial(5)}\")\nprint(f\"GCD of 48 and 18: {math.gcd(48, 18)}\")\n\n# Logarithmic functions\nprint(f\"\\nLogarithmic Functions:\")\nprint(f\"Natural log of e: {math.log(math.e)}\")\nprint(f\"Log base 10 of 1000: {math.log10(1000)}\")\nprint(f\"Log base 2 of 8: {math.log(8, 2)}\")\nprint(f\"e raised to power 2: {math.exp(2)}\")\n\n# Trigonometric functions\nprint(f\"\\nTrigonometric Functions:\")\nangle_degrees = 45\nangle_radians = math.radians(angle_degrees)\nprint(f\"45 degrees in radians: {angle_radians}\")\nprint(f\"sin(45°): {math.sin(angle_radians)}\")\nprint(f\"cos(45°): {math.cos(angle_radians)}\")\nprint(f\"tan(45°): {math.tan(angle_radians)}\")\n\n# Convert back to degrees\nprint(f\"atan(1) in degrees: {math.degrees(math.atan(1))}\")\n\n# Special functions\nprint(f\"\\nSpecial Functions:\")\nprint(f\"Distance formula (hypot): {math.hypot(3, 4)}\")  # √(3² + 4²)\nprint(f\"Gamma function Γ(5): {math.gamma(5)}\")  # (5-1)! = 24\nprint(f\"Is 5.0 finite? {math.isfinite(5.0)}\")\nprint(f\"Is inf finite? {math.isfinite(math.inf)}\")\nprint(f\"Is nan a number? {math.isnan(math.nan)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "5709510d",
   "metadata": {},
   "outputs": [],
   "source": "## 3. Random Module - Generate Random Numbers & Choices\n\nThe `random` module implements pseudo-random number generators for various distributions. It's essential for simulations, games, statistical sampling, and cryptographic applications (though use `secrets` for cryptographic purposes).\n\n**Key Functions:**\n- **Basic random numbers**: `random()`, `uniform()`, `randint()`, `randrange()`\n- **Sequences**: `choice()`, `choices()`, `sample()`, `shuffle()`\n- **Distributions**: `gauss()`, `normalvariate()`, `expovariate()`, `triangular()`\n- **Seeding**: `seed()`, `getstate()`, `setstate()`"
  },
  {
   "cell_type": "code",
   "id": "x7uq6dkrcjn",
   "source": "import random\n\n# Set seed for reproducible results\nrandom.seed(42)\n\n# Basic random number generation\nprint(\"Basic Random Numbers:\")\nprint(f\"Random float [0.0, 1.0): {random.random()}\")\nprint(f\"Random integer [1, 10]: {random.randint(1, 10)}\")\nprint(f\"Random integer [0, 10): {random.randrange(10)}\")\nprint(f\"Random integer [5, 15) step 2: {random.randrange(5, 15, 2)}\")\nprint(f\"Random uniform [2.5, 7.5]: {random.uniform(2.5, 7.5)}\")\n\n# Working with sequences\nfruits = ['apple', 'banana', 'cherry', 'date', 'elderberry']\ncolors = ['red', 'green', 'blue', 'yellow', 'purple', 'orange']\n\nprint(f\"\\nWorking with Sequences:\")\nprint(f\"Random choice from fruits: {random.choice(fruits)}\")\nprint(f\"3 random choices with replacement: {random.choices(fruits, k=3)}\")\nprint(f\"2 random choices without replacement: {random.sample(fruits, k=2)}\")\n\n# Weighted choices\nweights = [10, 1, 1, 1, 1]  # Apple is 10x more likely\nprint(f\"Weighted random choices: {random.choices(fruits, weights=weights, k=5)}\")\n\n# Shuffle in place\ndeck = list(range(1, 14))  # Cards 1-13\nprint(f\"Original deck: {deck}\")\nrandom.shuffle(deck)\nprint(f\"Shuffled deck: {deck}\")\n\n# Statistical distributions\nprint(f\"\\nStatistical Distributions:\")\nprint(f\"Gaussian (μ=0, σ=1): {random.gauss(0, 1):.3f}\")\nprint(f\"Normal (μ=100, σ=15): {random.normalvariate(100, 15):.1f}\")\nprint(f\"Exponential (λ=0.2): {random.expovariate(0.2):.3f}\")\nprint(f\"Triangular [0, 10, mode=7]: {random.triangular(0, 10, 7):.2f}\")\n\n# Generate random data for simulation\nprint(f\"\\nSimulation Example - Rolling dice 10 times:\")\ndice_rolls = [random.randint(1, 6) for _ in range(10)]\nprint(f\"Rolls: {dice_rolls}\")\nprint(f\"Average: {sum(dice_rolls)/len(dice_rolls):.2f}\")\n\n# Random password generation (simple example)\nimport string\npassword_chars = string.ascii_letters + string.digits + \"!@#$%\"\nrandom_password = ''.join(random.choices(password_chars, k=12))\nprint(f\"Random password: {random_password}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "dd5df283",
   "metadata": {},
   "outputs": [],
   "source": "## 4. OS Module - Operating System Interface\n\nThe `os` module provides a portable way of using operating system dependent functionality. It handles file paths, directories, environment variables, and process management across different platforms.\n\n**Key Categories:**\n- **File and directory operations**: `listdir()`, `mkdir()`, `rmdir()`, `rename()`, `remove()`\n- **Path operations**: `getcwd()`, `chdir()`, `path.join()`, `path.exists()`\n- **Environment variables**: `environ`, `getenv()`, `putenv()`\n- **Process management**: `system()`, `exec*()`, `fork()` (Unix only)\n- **File permissions**: `chmod()`, `stat()`, `access()`"
  },
  {
   "cell_type": "code",
   "id": "dfots3miicq",
   "source": "import os\nimport stat\n\n# Current working directory\nprint(\"Directory Operations:\")\ncurrent_dir = os.getcwd()\nprint(f\"Current working directory: {current_dir}\")\n\n# List directory contents\nprint(f\"\\nContents of current directory:\")\ncontents = os.listdir('.')\nfor item in contents[:5]:  # Show first 5 items\n    full_path = os.path.join('.', item)\n    if os.path.isdir(full_path):\n        print(f\"[DIR]  {item}\")\n    else:\n        print(f\"[FILE] {item}\")\n\n# Path operations\nsample_path = os.path.join('folder', 'subfolder', 'file.txt')\nprint(f\"\\nPath Operations:\")\nprint(f\"Joined path: {sample_path}\")\nprint(f\"Directory name: {os.path.dirname(sample_path)}\")\nprint(f\"Base name: {os.path.basename(sample_path)}\")\nprint(f\"Split extension: {os.path.splitext(sample_path)}\")\n\n# Check if path exists\nprint(f\"Current directory exists: {os.path.exists('.')}\")\nprint(f\"Sample path exists: {os.path.exists(sample_path)}\")\n\n# Environment variables\nprint(f\"\\nEnvironment Variables:\")\nprint(f\"PATH variable (first 100 chars): {os.environ.get('PATH', 'Not found')[:100]}...\")\nprint(f\"HOME/USERPROFILE: {os.environ.get('HOME') or os.environ.get('USERPROFILE', 'Not found')}\")\nprint(f\"Python path: {os.environ.get('PYTHONPATH', 'Not set')}\")\n\n# Set environment variable\nos.environ['MY_CUSTOM_VAR'] = 'Hello World'\nprint(f\"Custom variable: {os.getenv('MY_CUSTOM_VAR')}\")\n\n# File statistics (if we have any files)\nif contents:\n    first_file = None\n    for item in contents:\n        if os.path.isfile(item):\n            first_file = item\n            break\n    \n    if first_file:\n        print(f\"\\nFile Statistics for '{first_file}':\")\n        file_stats = os.stat(first_file)\n        print(f\"Size: {file_stats.st_size} bytes\")\n        print(f\"Modified time: {file_stats.st_mtime}\")\n        print(f\"Is readable: {os.access(first_file, os.R_OK)}\")\n        print(f\"Is writable: {os.access(first_file, os.W_OK)}\")\n        print(f\"Is executable: {os.access(first_file, os.X_OK)}\")\n\n# Platform information\nprint(f\"\\nPlatform Information:\")\nprint(f\"Operating system: {os.name}\")\nprint(f\"Platform: {os.sys.platform}\")\nprint(f\"Path separator: '{os.sep}'\")\nprint(f\"Line separator: {repr(os.linesep)}\")\n\n# Create and remove directory (safely)\ntest_dir = 'temp_test_dir'\nif not os.path.exists(test_dir):\n    os.mkdir(test_dir)\n    print(f\"\\nCreated directory: {test_dir}\")\n    print(f\"Directory exists: {os.path.exists(test_dir)}\")\n    os.rmdir(test_dir)\n    print(f\"Removed directory: {test_dir}\")\n    print(f\"Directory exists after removal: {os.path.exists(test_dir)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df42b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder\n",
    "os.mkdir('test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614465e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'destination.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High level operations on files and collection of files\n",
    "import shutil\n",
    "\n",
    "shutil.copyfile('source.txt', 'destination.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213900b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Krish\", \"age\": 25}\n",
      "<class 'str'>\n",
      "{'name': 'Krish', 'age': 25}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Data serialization\n",
    "import json\n",
    "\n",
    "data = {\"name\": \"Krish\", \"age\": 25}\n",
    "\n",
    "json_str = json.dumps(data)\n",
    "print(json_str)\n",
    "print(type(json_str))\n",
    "\n",
    "parsed_data = json.loads(json_str)\n",
    "\n",
    "print(parsed_data)\n",
    "print(type(parsed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f075f453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'age']\n",
      "['Krish', '32']\n"
     ]
    }
   ],
   "source": [
    "# csv\n",
    "import csv\n",
    "\n",
    "with open(\"example.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"name\", \"age\"])\n",
    "    writer.writerow([\"Krish\", 32])\n",
    "\n",
    "with open('example.csv', mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        print(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdfa5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 02:00:51.597215\n",
      "2025-08-25 02:00:51.597215\n"
     ]
    }
   ],
   "source": [
    "# datetime\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "now = datetime.now()\n",
    "print(now)\n",
    "\n",
    "yesterday = now - timedelta(days=1)\n",
    "\n",
    "print(yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d719c041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1756153928.8714025\n",
      "1756153928.8714025\n",
      "1756153930.871981\n"
     ]
    }
   ],
   "source": [
    "# time\n",
    "\n",
    "import time\n",
    "print(time.time())\n",
    "\n",
    "print(time.time())\n",
    "time.sleep(2)\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9550526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "# Regular expression\n",
    "\n",
    "import re\n",
    "\n",
    "pattern = r\"\\d+\"\n",
    "\n",
    "text = \"There are 123 apples 456\"\n",
    "\n",
    "match = re.search(pattern, text)\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "73261e62",
   "metadata": {},
   "outputs": [],
   "source": "## Additional Essential Standard Library Modules\n\nLet's explore more powerful modules that are frequently used in Python programming."
  },
  {
   "cell_type": "markdown",
   "id": "lymae2vta1s",
   "source": "## 5. Collections Module - Specialized Container Datatypes\n\nThe `collections` module provides specialized container datatypes that extend beyond the built-in types (`list`, `dict`, `set`, `tuple`). These are highly optimized and provide additional functionality.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "lhht8c5w27",
   "source": "from collections import Counter, defaultdict, deque, namedtuple, OrderedDict, ChainMap\n\n# Counter - Count hashable objects\nprint(\"=== Counter - Counting Made Easy ===\")\ntext = \"hello world python programming\"\nletter_counter = Counter(text.replace(\" \", \"\"))\nprint(f\"Letter frequencies: {letter_counter}\")\nprint(f\"Most common 3 letters: {letter_counter.most_common(3)}\")\n\n# Count items in a list\nfruits = ['apple', 'banana', 'apple', 'cherry', 'banana', 'apple']\nfruit_counter = Counter(fruits)\nprint(f\"Fruit counts: {fruit_counter}\")\nprint(f\"Apple count: {fruit_counter['apple']}\")\n\n# Counter arithmetic\ncounter1 = Counter(['a', 'b', 'c', 'a'])\ncounter2 = Counter(['a', 'b', 'b', 'd'])\nprint(f\"Counter1 + Counter2: {counter1 + counter2}\")\nprint(f\"Counter1 - Counter2: {counter1 - counter2}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# defaultdict - Dictionary with default values\nprint(\"=== defaultdict - Dictionary with Default Values ===\")\n# Regular dict would raise KeyError for missing keys\ndd_list = defaultdict(list)\ndd_int = defaultdict(int)\ndd_set = defaultdict(set)\n\n# Group items by their first letter\nwords = ['apple', 'banana', 'cherry', 'apricot', 'blueberry', 'avocado']\nfor word in words:\n    dd_list[word[0]].append(word)\n\nprint(f\"Words grouped by first letter: {dict(dd_list)}\")\n\n# Count with defaultdict\nfor char in \"hello world\":\n    if char != ' ':\n        dd_int[char] += 1\nprint(f\"Character count: {dict(dd_int)}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# deque - Double-ended queue (efficient operations at both ends)\nprint(\"=== deque - Double-ended Queue ===\")\ndq = deque(['middle'])\nprint(f\"Initial deque: {dq}\")\n\n# Add to both ends\ndq.appendleft('left')\ndq.append('right')\ndq.appendleft('far-left')\ndq.append('far-right')\nprint(f\"After adding to both ends: {dq}\")\n\n# Remove from both ends\nleft_item = dq.popleft()\nright_item = dq.pop()\nprint(f\"Removed '{left_item}' from left and '{right_item}' from right\")\nprint(f\"Remaining: {dq}\")\n\n# Rotate the deque\ndq.rotate(1)  # Rotate right by 1\nprint(f\"After rotating right by 1: {dq}\")\ndq.rotate(-2)  # Rotate left by 2\nprint(f\"After rotating left by 2: {dq}\")\n\n# Sliding window example\ndef sliding_window_max(arr, window_size):\n    dq = deque()\n    result = []\n    for i, val in enumerate(arr):\n        # Remove elements outside current window\n        while dq and dq[0] <= i - window_size:\n            dq.popleft()\n        # Remove smaller elements from the back\n        while dq and arr[dq[-1]] <= val:\n            dq.pop()\n        dq.append(i)\n        if i >= window_size - 1:\n            result.append(arr[dq[0]])\n    return result\n\nnumbers = [1, 3, 2, 5, 8, 7, 6, 4]\nprint(f\"Sliding window max (window=3): {sliding_window_max(numbers, 3)}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# namedtuple - Immutable objects with named fields\nprint(\"=== namedtuple - Structured Data ===\")\nPerson = namedtuple('Person', ['name', 'age', 'city'])\nPoint = namedtuple('Point', 'x y')\n\n# Create instances\nperson1 = Person('Alice', 30, 'New York')\nperson2 = Person('Bob', 25, 'San Francisco')\npoint1 = Point(3, 4)\n\nprint(f\"Person 1: {person1}\")\nprint(f\"Person 1 name: {person1.name}, age: {person1.age}\")\nprint(f\"Point: {point1}, distance from origin: {(point1.x**2 + point1.y**2)**0.5}\")\n\n# Convert to dictionary\nprint(f\"Person as dict: {person1._asdict()}\")\n\n# Create new instance with some fields changed\nperson1_older = person1._replace(age=31)\nprint(f\"Person 1 after birthday: {person1_older}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# ChainMap - Combine multiple dictionaries\nprint(\"=== ChainMap - Combine Multiple Mappings ===\")\ndefaults = {'color': 'red', 'user': 'guest'}\nenvironment = {'user': 'admin', 'path': '/usr/bin'}\ncommand_line = {'user': 'john', 'debug': True}\n\n# Chain maps (later maps override earlier ones for keys)\ncombined = ChainMap(command_line, environment, defaults)\nprint(f\"Combined settings: {dict(combined)}\")\nprint(f\"User (from command_line): {combined['user']}\")\nprint(f\"Color (from defaults): {combined['color']}\")\nprint(f\"Path (from environment): {combined['path']}\")\n\n# Show which map a key comes from\nprint(f\"Maps: {combined.maps}\")\nprint(f\"All keys: {list(combined.keys())}\")\n\n# Add new child map\nnew_config = {'theme': 'dark', 'user': 'superuser'}\ncombined = combined.new_child(new_config)\nprint(f\"After adding new child: {dict(combined)}\")\nprint(f\"User now: {combined['user']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "v0lxkja06qr",
   "source": "## 6. Itertools Module - Iterator Building Blocks\n\nThe `itertools` module provides functions for creating iterators for efficient looping. These tools are memory efficient and fast, making them perfect for processing large datasets.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4ds3th4843u",
   "source": "import itertools\n\nprint(\"=== Infinite Iterators ===\")\n# count - infinite arithmetic sequence\ncounter = itertools.count(start=10, step=3)\nprint(\"First 5 numbers from count(10, 3):\", list(itertools.islice(counter, 5)))\n\n# cycle - infinite repetition\ncolors = itertools.cycle(['red', 'green', 'blue'])\nprint(\"First 8 from cycling colors:\", list(itertools.islice(colors, 8)))\n\n# repeat - repeat a value\nrepeated = itertools.repeat('hello', 4)\nprint(\"Repeat 'hello' 4 times:\", list(repeated))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Iterators terminating on shortest input ===\")\n# chain - flatten iterables\nlist1 = [1, 2, 3]\nlist2 = ['a', 'b', 'c']\nlist3 = [10, 20]\nchained = itertools.chain(list1, list2, list3)\nprint(\"Chained lists:\", list(chained))\n\n# compress - filter based on selectors\ndata = ['A', 'B', 'C', 'D', 'E']\nselectors = [1, 0, 1, 0, 1]  # 1 = include, 0 = exclude\ncompressed = itertools.compress(data, selectors)\nprint(\"Compressed data:\", list(compressed))\n\n# dropwhile and takewhile\nnumbers = [1, 3, 5, 8, 9, 11, 12, 15]\ndropped = itertools.dropwhile(lambda x: x < 8, numbers)\nprint(\"Drop while < 8:\", list(dropped))\n\ntaken = itertools.takewhile(lambda x: x < 10, numbers)\nprint(\"Take while < 10:\", list(taken))\n\n# filterfalse - opposite of filter\nfiltered = itertools.filterfalse(lambda x: x % 2 == 0, range(10))\nprint(\"Filter out even numbers:\", list(filtered))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Combinatorial Iterators ===\")\n# product - Cartesian product\ncolors = ['red', 'blue']\nsizes = ['S', 'M', 'L']\nproducts = itertools.product(colors, sizes)\nprint(\"Product of colors and sizes:\", list(products))\n\n# permutations - all possible orderings\nletters = ['A', 'B', 'C']\nperms = itertools.permutations(letters, 2)  # length 2\nprint(\"Permutations of ABC (length 2):\", list(perms))\n\n# combinations - choose r items from n (order doesn't matter)\ncombs = itertools.combinations(letters, 2)\nprint(\"Combinations of ABC (choose 2):\", list(combs))\n\n# combinations_with_replacement\ncombs_rep = itertools.combinations_with_replacement([1, 2, 3], 2)\nprint(\"Combinations with replacement:\", list(combs_rep))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Grouping and Aggregation ===\")\n# groupby - group consecutive elements by key function\ndata = [('Alice', 25), ('Bob', 25), ('Charlie', 30), ('Diana', 30), ('Eve', 25)]\ndata_by_age = itertools.groupby(data, key=lambda x: x[1])\nfor age, group in data_by_age:\n    people = list(group)\n    print(f\"Age {age}: {[person[0] for person in people]}\")\n\n# accumulate - running totals\nnumbers = [1, 2, 3, 4, 5]\nrunning_sum = itertools.accumulate(numbers)\nprint(f\"Running sum: {list(running_sum)}\")\n\nrunning_product = itertools.accumulate(numbers, lambda x, y: x * y)\nprint(f\"Running product: {list(running_product)}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Practical Examples ===\")\n\n# Example 1: Batch processing\ndef batched(iterable, batch_size):\n    iterator = iter(iterable)\n    while True:\n        batch = list(itertools.islice(iterator, batch_size))\n        if not batch:\n            break\n        yield batch\n\nlarge_list = list(range(23))\nprint(\"Process in batches of 5:\")\nfor i, batch in enumerate(batched(large_list, 5)):\n    print(f\"Batch {i+1}: {batch}\")\n\n# Example 2: Sliding window\ndef sliding_window(iterable, window_size):\n    iterators = itertools.tee(iterable, window_size)\n    for i, iterator in enumerate(iterators):\n        # Advance each iterator by i positions\n        for _ in range(i):\n            next(iterator, None)\n    return zip(*iterators)\n\ntext = \"ABCDEF\"\nprint(f\"\\nSliding window of size 3 on '{text}':\")\nfor window in sliding_window(text, 3):\n    print(''.join(window))\n\n# Example 3: Round-robin processing\ndef round_robin(*iterables):\n    iterators = [iter(it) for it in iterables]\n    while iterators:\n        for it in list(iterators):\n            try:\n                yield next(it)\n            except StopIteration:\n                iterators.remove(it)\n\nlists = [[1, 2, 3], ['A', 'B'], ['x', 'y', 'z', 'w']]\nprint(f\"\\nRound-robin from {lists}:\")\nprint(list(round_robin(*lists)))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "nh2hgu5srbk",
   "source": "## 7. Functools Module - Higher-Order Functions and Operations on Callable Objects\n\nThe `functools` module provides utilities for working with higher-order functions and operations on callable objects.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "oxf231ewnw",
   "source": "import functools\nimport time\nfrom operator import add, mul\n\nprint(\"=== reduce - Apply function cumulatively ===\")\n# reduce applies a function cumulatively to items in a sequence\nnumbers = [1, 2, 3, 4, 5]\nsum_result = functools.reduce(add, numbers)\nproduct_result = functools.reduce(mul, numbers)\nprint(f\"Sum of {numbers}: {sum_result}\")\nprint(f\"Product of {numbers}: {product_result}\")\n\n# Find maximum with reduce\nmax_result = functools.reduce(lambda x, y: x if x > y else y, numbers)\nprint(f\"Maximum: {max_result}\")\n\n# Concatenate strings\nwords = ['Hello', ' ', 'Python', ' ', 'World']\nsentence = functools.reduce(add, words)\nprint(f\"Concatenated: '{sentence}'\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== lru_cache - Least Recently Used Cache ===\")\n# Cache expensive function calls\n@functools.lru_cache(maxsize=128)\ndef fibonacci(n):\n    if n < 2:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\n@functools.lru_cache(maxsize=None)  # Unlimited cache\ndef expensive_function(x, y):\n    time.sleep(0.1)  # Simulate expensive operation\n    return x * y + x ** 2\n\n# Test fibonacci with caching\nstart_time = time.time()\nresult = fibonacci(30)\nend_time = time.time()\nprint(f\"Fibonacci(30) = {result}, Time: {end_time - start_time:.4f}s\")\n\n# Check cache info\nprint(f\"Fibonacci cache info: {fibonacci.cache_info()}\")\n\n# Test expensive function\nstart_time = time.time()\nresult1 = expensive_function(5, 10)\nresult2 = expensive_function(5, 10)  # Should be cached\nend_time = time.time()\nprint(f\"Expensive function results: {result1}, {result2}\")\nprint(f\"Time for both calls: {end_time - start_time:.4f}s\")\nprint(f\"Expensive function cache info: {expensive_function.cache_info()}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== partial - Partial Function Application ===\")\n# Create specialized versions of functions\ndef multiply(x, y, z):\n    return x * y * z\n\n# Create partial functions\ndouble = functools.partial(multiply, 2)  # Fix first argument to 2\nmultiply_by_10 = functools.partial(multiply, y=10)  # Fix y argument to 10\n\nprint(f\"Double of 5*3: {double(5, 3)}\")  # 2 * 5 * 3 = 30\nprint(f\"Multiply 3*10*4: {multiply_by_10(3, 4)}\")  # 3 * 10 * 4 = 120\n\n# Partial with built-in functions\nfrom operator import pow\nsquare = functools.partial(pow, exp=2)  # x^2\ncube = functools.partial(pow, exp=3)    # x^3\n\nprint(f\"Square of 5: {square(5)}\")\nprint(f\"Cube of 4: {cube(4)}\")\n\n# Practical example: logging with different levels\ndef log_message(level, message, timestamp=None):\n    ts = timestamp or time.strftime('%Y-%m-%d %H:%M:%S')\n    return f\"[{ts}] {level}: {message}\"\n\ninfo_log = functools.partial(log_message, \"INFO\")\nerror_log = functools.partial(log_message, \"ERROR\")\n\nprint(info_log(\"Application started\"))\nprint(error_log(\"Database connection failed\"))\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== singledispatch - Single Dispatch Generic Functions ===\")\n# Create generic functions that behave differently based on type\n@functools.singledispatch\ndef process_data(arg):\n    print(f\"Processing generic data: {arg}\")\n\n@process_data.register\ndef _(arg: int):\n    print(f\"Processing integer: {arg}, squared: {arg**2}\")\n\n@process_data.register\ndef _(arg: str):\n    print(f\"Processing string: '{arg}', length: {len(arg)}\")\n\n@process_data.register\ndef _(arg: list):\n    print(f\"Processing list: {arg}, sum: {sum(arg) if all(isinstance(x, (int, float)) for x in arg) else 'N/A'}\")\n\n@process_data.register\ndef _(arg: dict):\n    print(f\"Processing dictionary: {len(arg)} items, keys: {list(arg.keys())}\")\n\n# Test with different types\nprocess_data(42)\nprocess_data(\"Hello World\")\nprocess_data([1, 2, 3, 4, 5])\nprocess_data({\"name\": \"Alice\", \"age\": 30})\nprocess_data(3.14)  # Falls back to generic\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== wraps - Decorator Helper ===\")\n# Properly preserve function metadata in decorators\ndef my_decorator(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        print(f\"Calling {func.__name__}\")\n        result = func(*args, **kwargs)\n        print(f\"Finished {func.__name__}\")\n        return result\n    return wrapper\n\n@my_decorator\ndef greet(name):\n    \\\"\\\"\\\"Greet someone by name\\\"\\\"\\\"\n    return f\"Hello, {name}!\"\n\n# Without @functools.wraps, we would lose function metadata\nprint(f\"Function name: {greet.__name__}\")\nprint(f\"Function doc: {greet.__doc__}\")\nresult = greet(\"Alice\")\nprint(f\"Result: {result}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== cached_property - Cached Property Decorator ===\")\nclass DataProcessor:\n    def __init__(self, data):\n        self.data = data\n    \n    @functools.cached_property\n    def processed_data(self):\n        print(\"Processing data... (expensive operation)\")\n        time.sleep(0.1)  # Simulate expensive processing\n        return [x * 2 for x in self.data]\n    \n    @functools.cached_property  \n    def data_summary(self):\n        print(\"Calculating summary... (expensive operation)\")\n        time.sleep(0.1)\n        return {\n            'count': len(self.data),\n            'sum': sum(self.data),\n            'average': sum(self.data) / len(self.data)\n        }\n\nprocessor = DataProcessor([1, 2, 3, 4, 5])\n\n# First access - computes the value\nprint(\"First access to processed_data:\")\nprint(processor.processed_data)\n\n# Second access - uses cached value\nprint(\"\\nSecond access to processed_data:\")\nprint(processor.processed_data)\n\nprint(\"\\nFirst access to data_summary:\")\nprint(processor.data_summary)\n\nprint(\"\\nSecond access to data_summary:\")\nprint(processor.data_summary)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c4f3soqee",
   "source": "## 8. Pathlib Module - Object-Oriented File System Paths\n\nThe `pathlib` module provides a more modern, object-oriented approach to working with file system paths. It's more readable and cross-platform than the older `os.path` module.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "a0fseyvgy6",
   "source": "from pathlib import Path\nimport os\n\nprint(\"=== Path Creation and Basic Operations ===\")\n# Create path objects\ncurrent_path = Path('.')\nhome_path = Path.home()\ncwd_path = Path.cwd()\n\nprint(f\"Current directory: {current_path.resolve()}\")\nprint(f\"Home directory: {home_path}\")\nprint(f\"Working directory: {cwd_path}\")\n\n# Join paths using the / operator\nconfig_path = home_path / \"config\" / \"settings.json\"\nprint(f\"Config path: {config_path}\")\n\n# Create paths from strings\ndata_path = Path(\"data/files/document.txt\")\nprint(f\"Data path: {data_path}\")\nprint(f\"Absolute path: {data_path.resolve()}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Path Properties and Attributes ===\")\nsample_path = Path(\"/Users/john/documents/project/report.pdf\")\n\nprint(f\"Full path: {sample_path}\")\nprint(f\"Name (filename): {sample_path.name}\")\nprint(f\"Stem (without extension): {sample_path.stem}\")\nprint(f\"Suffix (extension): {sample_path.suffix}\")\nprint(f\"Suffixes (all extensions): {sample_path.suffixes}\")\nprint(f\"Parent directory: {sample_path.parent}\")\nprint(f\"Grandparent: {sample_path.parent.parent}\")\nprint(f\"All parents: {list(sample_path.parents)}\")\nprint(f\"Root: {sample_path.root}\")\nprint(f\"Anchor: {sample_path.anchor}\")\nprint(f\"Parts: {sample_path.parts}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Path Checking and Querying ===\")\n# Check current directory contents\ncurrent_dir = Path('.')\nprint(\"Checking current directory...\")\n\nprint(f\"Exists: {current_dir.exists()}\")\nprint(f\"Is directory: {current_dir.is_dir()}\")\nprint(f\"Is file: {current_dir.is_file()}\")\n\n# List contents\nprint(f\"\\nContents of current directory:\")\ntry:\n    for item in current_dir.iterdir():\n        if item.is_dir():\n            print(f\"[DIR]  {item.name}\")\n        else:\n            print(f\"[FILE] {item.name}\")\n        if len(list(current_dir.iterdir())) > 10:  # Limit output\n            print(\"... (and more)\")\n            break\nexcept PermissionError:\n    print(\"Permission denied to list directory\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== File Operations ===\")\n# Create a temporary file for demonstration\ntemp_file = Path(\"temp_demo.txt\")\n\n# Write to file\ntemp_file.write_text(\"Hello, World!\\nThis is a test file.\\nPython pathlib is great!\")\nprint(f\"Created file: {temp_file}\")\nprint(f\"File exists: {temp_file.exists()}\")\nprint(f\"File size: {temp_file.stat().st_size} bytes\")\n\n# Read from file\ncontent = temp_file.read_text()\nprint(f\"File content:\\n{content}\")\n\n# Read lines\nlines = temp_file.read_text().splitlines()\nprint(f\"Number of lines: {len(lines)}\")\nprint(f\"First line: {lines[0]}\")\n\n# File metadata\nstat = temp_file.stat()\nimport datetime\nmodification_time = datetime.datetime.fromtimestamp(stat.st_mtime)\nprint(f\"Last modified: {modification_time}\")\nprint(f\"File permissions: {oct(stat.st_mode)}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Pattern Matching and Globbing ===\")\n# Use glob patterns to find files\nprint(\"Files matching '*.py':\")\npy_files = list(Path('.').glob('*.py'))\nfor py_file in py_files[:5]:  # Show first 5\n    print(f\"  {py_file}\")\n\nprint(f\"\\nFiles matching '**/*.ipynb' (recursive):\")\nnotebook_files = list(Path('.').rglob('*.ipynb'))\nfor notebook in notebook_files[:3]:  # Show first 3\n    print(f\"  {notebook}\")\n\n# Pattern matching with match()\ntest_files = [\n    \"document.txt\",\n    \"image.png\", \n    \"script.py\",\n    \"data.json\",\n    \"backup.txt.bak\"\n]\n\nprint(f\"\\nPattern matching examples:\")\nfor filename in test_files:\n    path = Path(filename)\n    if path.match(\"*.txt\"):\n        print(f\"  {filename} is a text file\")\n    elif path.match(\"*.p*\"):\n        print(f\"  {filename} starts with 'p' extension\") \n    elif path.match(\"*.json\"):\n        print(f\"  {filename} is a JSON file\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Path Manipulation ===\")\n# Change file extension\noriginal = Path(\"document.txt\")\nnew_extension = original.with_suffix(\".md\")\nprint(f\"Original: {original}\")\nprint(f\"With new extension: {new_extension}\")\n\n# Change filename but keep extension\nnew_name = original.with_name(\"README.txt\")\nprint(f\"With new name: {new_name}\")\n\n# Change stem (name without extension)\nnew_stem = original.with_stem(\"manual\")\nprint(f\"With new stem: {new_stem}\")\n\n# Relative paths\nbase_path = Path(\"/Users/john/projects\")\nfull_path = Path(\"/Users/john/projects/myapp/src/main.py\")\ntry:\n    relative = full_path.relative_to(base_path)\n    print(f\"Relative path: {relative}\")\nexcept ValueError as e:\n    print(f\"Cannot compute relative path: {e}\")\n\n# Resolve and normalize paths\nmessy_path = Path(\"./folder/../folder/./file.txt\")\nclean_path = messy_path.resolve()\nprint(f\"Messy path: {messy_path}\")\nprint(f\"Resolved path: {clean_path}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"=== Practical Examples ===\")\n# Example 1: Find all Python files and their sizes\nprint(\"Python files and their sizes:\")\npython_files = Path('.').rglob('*.py')\ntotal_size = 0\nfile_count = 0\nfor py_file in python_files:\n    if py_file.is_file():\n        size = py_file.stat().st_size\n        print(f\"  {py_file}: {size} bytes\")\n        total_size += size\n        file_count += 1\n        if file_count >= 5:  # Limit output\n            break\n\nprint(f\"Total size of {file_count} Python files: {total_size} bytes\")\n\n# Example 2: Backup files (simulate)\ndef backup_path(original_path):\n    \\\"\\\"\\\"Generate backup filename\\\"\\\"\\\"\n    path = Path(original_path)\n    backup_name = f\"{path.stem}_backup{path.suffix}\"\n    return path.with_name(backup_name)\n\nfiles_to_backup = [\"document.txt\", \"script.py\", \"data.json\"]\nprint(f\"\\nBackup filename examples:\")\nfor filename in files_to_backup:\n    backup = backup_path(filename)\n    print(f\"  {filename} -> {backup}\")\n\n# Example 3: Create directory structure\nproject_structure = Path(\"my_project\")\ndirectories = [\n    \"src\",\n    \"tests\", \n    \"docs\",\n    \"config\"\n]\n\nprint(f\"\\nCreating project structure:\")\nfor directory in directories:\n    dir_path = project_structure / directory\n    print(f\"  Would create: {dir_path}\")\n    # Uncomment to actually create: dir_path.mkdir(parents=True, exist_ok=True)\n\n# Clean up\nif temp_file.exists():\n    temp_file.unlink()\n    print(f\"\\nCleaned up temporary file: {temp_file}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0d9iu7f57r2f",
   "source": "## 9. Advanced Topics and Best Practices\n\n### Performance Considerations\n\nWhen working with the standard library, consider these performance tips:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "exxnyjqitda",
   "source": "import timeit\nimport sys\nfrom collections import deque\nfrom pathlib import Path\n\nprint(\"=== Performance Comparisons ===\")\n\n# 1. List vs deque for adding to front\nprint(\"1. Adding 10,000 items to the front:\")\n\n# Test with list (slow)\ndef list_append_left():\n    lst = []\n    for i in range(10000):\n        lst.insert(0, i)\n    return lst\n\n# Test with deque (fast)\ndef deque_append_left():\n    dq = deque()\n    for i in range(10000):\n        dq.appendleft(i)\n    return dq\n\nlist_time = timeit.timeit(list_append_left, number=1)\ndeque_time = timeit.timeit(deque_append_left, number=1)\n\nprint(f\"  List insert(0, x): {list_time:.4f} seconds\")\nprint(f\"  deque.appendleft(x): {deque_time:.4f} seconds\")\nprint(f\"  deque is {list_time/deque_time:.1f}x faster\")\n\n# 2. String concatenation methods\nprint(f\"\\n2. String concatenation (1000 strings):\")\n\ndef string_concat_plus():\n    result = \"\"\n    for i in range(1000):\n        result += f\"item{i} \"\n    return result\n\ndef string_concat_join():\n    items = []\n    for i in range(1000):\n        items.append(f\"item{i}\")\n    return \" \".join(items)\n\nplus_time = timeit.timeit(string_concat_plus, number=10)\njoin_time = timeit.timeit(string_concat_join, number=10)\n\nprint(f\"  String += : {plus_time:.4f} seconds\")\nprint(f\"  str.join(): {join_time:.4f} seconds\")\nprint(f\"  join() is {plus_time/join_time:.1f}x faster\")\n\n# 3. Membership testing: list vs set\nprint(f\"\\n3. Membership testing (10,000 items, 1000 lookups):\")\n\ndata_list = list(range(10000))\ndata_set = set(range(10000))\nlookups = list(range(0, 10000, 10))  # Every 10th item\n\ndef list_membership():\n    count = 0\n    for item in lookups:\n        if item in data_list:\n            count += 1\n    return count\n\ndef set_membership():\n    count = 0\n    for item in lookups:\n        if item in data_set:\n            count += 1\n    return count\n\nlist_membership_time = timeit.timeit(list_membership, number=10)\nset_membership_time = timeit.timeit(set_membership, number=10)\n\nprint(f\"  List membership: {list_membership_time:.4f} seconds\")\nprint(f\"  Set membership: {set_membership_time:.4f} seconds\")\nprint(f\"  Set is {list_membership_time/set_membership_time:.1f}x faster\")\n\nprint(\"\\n\" + \"=\"*60 + \"\\n\")\n\nprint(\"=== Memory Usage Patterns ===\")\n\n# Compare memory usage of different data structures\ndef get_size_mb(obj):\n    return sys.getsizeof(obj) / 1024 / 1024\n\n# Create different data structures with same data\ndata_size = 100000\nnumbers = list(range(data_size))\n\n# List\nlist_data = numbers.copy()\nlist_size = get_size_mb(list_data)\n\n# Array\nimport array\narray_data = array.array('i', numbers)\narray_size = get_size_mb(array_data)\n\n# Set\nset_data = set(numbers)\nset_size = get_size_mb(set_data)\n\nprint(f\"Memory usage for {data_size:,} integers:\")\nprint(f\"  List: {list_size:.2f} MB\")\nprint(f\"  Array: {array_size:.2f} MB\") \nprint(f\"  Set: {set_size:.2f} MB\")\nprint(f\"  Array is {list_size/array_size:.1f}x more memory efficient than list\")\n\nprint(\"\\n\" + \"=\"*60 + \"\\n\")\n\nprint(\"=== Best Practices Summary ===\")\n\nbest_practices = [\n    (\"Use collections.defaultdict\", \"Instead of checking if key exists before accessing\"),\n    (\"Use collections.Counter\", \"For counting hashable objects efficiently\"),\n    (\"Use collections.deque\", \"For efficient operations at both ends of sequence\"),\n    (\"Use pathlib.Path\", \"Instead of os.path for modern path operations\"),\n    (\"Use functools.lru_cache\", \"To cache expensive function calls\"),\n    (\"Use itertools\", \"For memory-efficient iteration patterns\"),\n    (\"Use array.array\", \"For large collections of numbers (memory efficiency)\"),\n    (\"Use set/frozenset\", \"For fast membership testing and unique collections\"),\n    (\"Use str.join()\", \"Instead of += for concatenating many strings\"),\n    (\"Use enumerate()\", \"Instead of range(len()) for indexed iteration\"),\n    (\"Use zip()\", \"For parallel iteration over multiple sequences\"),\n    (\"Use any()/all()\", \"For checking conditions across sequences\"),\n    (\"Use operator module\", \"For functional programming patterns\"),\n    (\"Use contextlib\", \"For resource management and custom context managers\"),\n    (\"Use logging\", \"Instead of print() for production code\"),\n]\n\nfor practice, reason in best_practices:\n    print(f\"✓ {practice:<30} - {reason}\")\n\nprint(\"\\n\" + \"=\"*60 + \"\\n\")\n\nprint(\"=== Module Import Best Practices ===\")\n\nprint(\\\"\\\"\\\"\n1. Import Order (PEP 8):\n   - Standard library imports first\n   - Related third-party imports second  \n   - Local application imports last\n   - Blank line between each group\n\n2. Import Styles:\n   ✓ import os\n   ✓ from collections import defaultdict, Counter\n   ✓ import numpy as np  # for third-party with common aliases\n   \n   ✗ from os import *  # Avoid star imports\n   ✗ import sys, os, re  # Avoid multiple imports on one line\n\n3. Conditional Imports:\n   - Use try/except for optional dependencies\n   - Import at module level when possible\n   - Use importlib for dynamic imports\n\n4. Performance:\n   - Import at module level, not inside functions (unless necessary)\n   - Use absolute imports over relative imports\n   - Consider lazy imports for heavy modules used conditionally\n\\\"\\\"\\\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pyov7makfm9",
   "source": "## 10. Quick Reference - Most Commonly Used Standard Library Modules\n\nHere's a quick reference guide for the modules you'll use most frequently:\n\n### Essential Modules (Use Daily)\n- **`os`** - Operating system interface (files, directories, environment)\n- **`sys`** - System-specific parameters and functions  \n- **`pathlib`** - Object-oriented file paths (modern alternative to os.path)\n- **`json`** - JSON encoder/decoder for web APIs and config files\n- **`re`** - Regular expressions for text pattern matching\n- **`datetime`** - Date and time handling\n- **`collections`** - Specialized container datatypes (Counter, defaultdict, deque)\n- **`itertools`** - Iterator building blocks for efficient loops\n- **`functools`** - Higher-order functions (lru_cache, partial, reduce)\n\n### Frequent Use (Weekly)\n- **`random`** - Generate random numbers and choices\n- **`math`** - Mathematical functions and constants  \n- **`csv`** - CSV file reading and writing\n- **`urllib`** - URL handling modules for HTTP requests\n- **`logging`** - Flexible logging system (better than print for production)\n- **`unittest`** - Unit testing framework\n- **`argparse`** - Command-line argument parsing\n- **`configparser`** - Configuration file parser\n\n### Specialized Use (As Needed)\n- **`array`** - Efficient arrays of numeric values\n- **`heapq`** - Heap queue algorithm (priority queue)\n- **`bisect`** - Array bisection algorithm (binary search)\n- **`statistics`** - Statistical functions\n- **`decimal`** - Decimal fixed point and floating point arithmetic\n- **`sqlite3`** - SQLite database interface\n- **`threading`** - Thread-based parallelism\n- **`multiprocessing`** - Process-based parallelism\n- **`asyncio`** - Asynchronous I/O framework\n- **`pickle`** - Python object serialization\n- **`xml`** - XML processing modules\n- **`http`** - HTTP modules for servers and clients\n\n### Learning Path Recommendation\n\n**Beginner (Start Here):**\n1. `os` and `pathlib` - File system operations\n2. `json` - Data exchange format\n3. `datetime` - Working with dates and times\n4. `random` - Adding randomness to programs\n5. `math` - Mathematical operations\n\n**Intermediate (Next Steps):**\n1. `collections` - Advanced data structures\n2. `itertools` - Efficient iteration patterns  \n3. `functools` - Functional programming tools\n4. `re` - Text pattern matching\n5. `csv` - Structured data files\n\n**Advanced (For Production Code):**\n1. `logging` - Professional logging\n2. `unittest` - Testing your code\n3. `argparse` - Command-line interfaces\n4. `threading`/`multiprocessing` - Concurrency\n5. `asyncio` - Asynchronous programming\n\nRemember: The standard library is vast (200+ modules), but mastering these core modules will cover 80% of your daily programming needs!",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}